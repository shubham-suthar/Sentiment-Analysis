{
  "cells": [
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "import numpy as np \nimport pandas as pd \n\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Embedding, LSTM, SpatialDropout1D\nfrom sklearn.model_selection import train_test_split\nfrom keras.utils.np_utils import to_categorical\nimport re",
      "execution_count": 11,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#data = pd.read_table('yelp_labelled.txt', names=('text', 'sentiment'))\n#data = data.applymap(str)\ndata = pd.read_csv('Tweets.csv') #read data\nlist(data.columns) #list of features\n#print(data)\ndata = data[['text','airline_sentiment']] #keep only neccessary features",
      "execution_count": 12,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "data = data[data.airline_sentiment != \"neutral\"] #remove samples with label neutral as we want only positive or negative\ndata['text'] = data['text'].apply(lambda x: x.lower()) #convert text to lowecase\ndata['text'] = data['text'].apply((lambda x: re.sub('[^a-zA-z0-9\\s]','',x))) #remove punctuations, special symbols and emojis\n\n#data[\"sentiment\"]= data[\"sentiment\"].replace(\"1\", \"positive\") \n#data[\"sentiment\"]= data[\"sentiment\"].replace(\"0\", \"negative\") \n\nprint(data[ data['airline_sentiment'] == 'positive'].size) #counts number of positive example\nprint(data[ data['airline_sentiment'] == 'negative'].size)\nfor idx,row in data.iterrows():\n    row[0] = row[0].replace('rt',' ')\n    \nmax_features = 5000 #maximum number of entries in dictionary built by tokenizer\ntokenizer = Tokenizer(num_words=max_features, split=' ') #split data\ntokenizer.fit_on_texts(data['text'].values)\nX = tokenizer.texts_to_sequences(data['text'].values) #convert sentences to vector form\nX = pad_sequences(X) #make all vectors of equal length",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": "4726\n18356\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "print(X.shape)",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": "(11541, 33)\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#build model\nembed_dim = 128\nlstm_out = 196\n\nmodel = Sequential() #create model\nmodel.add(Embedding(max_features, embed_dim,input_length = X.shape[1]))\nmodel.add(SpatialDropout1D(0.4)) #drops 40% nodes\nmodel.add(LSTM(lstm_out, dropout=0.2, recurrent_dropout=0.2)) #LSTM layer\nmodel.add(Dense(2,activation='softmax'))  # for classification\nmodel.compile(loss = 'categorical_crossentropy', optimizer='adam',metrics = ['accuracy']) #compile model\nprint(model.summary())",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": "_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nembedding_1 (Embedding)      (None, 33, 128)           640000    \n_________________________________________________________________\nspatial_dropout1d_1 (Spatial (None, 33, 128)           0         \n_________________________________________________________________\nlstm_1 (LSTM)                (None, 196)               254800    \n_________________________________________________________________\ndense_1 (Dense)              (None, 2)                 394       \n=================================================================\nTotal params: 895,194\nTrainable params: 895,194\nNon-trainable params: 0\n_________________________________________________________________\nNone\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "Y = pd.get_dummies(data['airline_sentiment']).values #connvert categorical labels to vector form\nX_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size = 0.33, random_state = 42) #split train and test data\nprint(X_train.shape,Y_train.shape)\nprint(X_test.shape,Y_test.shape)",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": "(7732, 33) (7732, 2)\n(3809, 33) (3809, 2)\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "batch_size = 32\nmodel.fit(X_train, Y_train, epochs = 10, batch_size=batch_size, verbose = 1) #fit model",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Epoch 1/10\n7732/7732 [==============================] - 59s 8ms/step - loss: 0.3334 - acc: 0.8619\nEpoch 2/10\n7732/7732 [==============================] - 52s 7ms/step - loss: 0.1795 - acc: 0.9325\nEpoch 3/10\n7732/7732 [==============================] - 62s 8ms/step - loss: 0.1257 - acc: 0.9519\nEpoch 4/10\n7732/7732 [==============================] - 59s 8ms/step - loss: 0.0894 - acc: 0.9665\nEpoch 5/10\n7732/7732 [==============================] - 55s 7ms/step - loss: 0.0697 - acc: 0.9732\nEpoch 6/10\n7732/7732 [==============================] - 63s 8ms/step - loss: 0.0543 - acc: 0.9828\nEpoch 7/10\n7732/7732 [==============================] - 48s 6ms/step - loss: 0.0400 - acc: 0.9846\nEpoch 8/10\n7732/7732 [==============================] - 50s 6ms/step - loss: 0.0367 - acc: 0.9867\nEpoch 9/10\n7732/7732 [==============================] - 51s 7ms/step - loss: 0.0337 - acc: 0.9881\nEpoch 10/10\n7732/7732 [==============================] - 56s 7ms/step - loss: 0.0265 - acc: 0.9909\n",
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "execution_count": 7,
          "data": {
            "text/plain": "<keras.callbacks.History at 0x7fb775cb40b8>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#Evaluate model\nvalidation_size = 500\n\nX_validate = X_test[-validation_size:]\nY_validate = Y_test[-validation_size:]\nX_test = X_test[:-validation_size]\nY_test = Y_test[:-validation_size]\nscore,acc = model.evaluate(X_test, Y_test, verbose = 1, batch_size = batch_size)\nprint(\"score: %.4f\" % (score))\nprint(\"Accuracy: %.4f\" % (acc))",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": "3309/3309 [==============================] - 6s 2ms/step\nscore: 0.4628\nAccuracy: 0.9178\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#compute specificity, sencitivity, precision, recall and F1-score\npos_cnt, neg_cnt, pos_correct, neg_correct, pos_incorrect, neg_incorrect = 0, 0, 0, 0, 0, 0\nfor x in range(len(X_validate)):\n    \n    result = model.predict(X_validate[x].reshape(1,X_test.shape[1]),batch_size=1,verbose = 2)[0]\n   \n    if np.argmax(result) == np.argmax(Y_validate[x]): #checks whether example is correctly classified\n        if np.argmax(Y_validate[x]) == 0: #checks if examples was classified as negative\n            neg_correct += 1\n        else:\n            pos_correct += 1\n            \n    else:\n        if np.argmax(Y_validate[x]) == 0:\n            neg_incorrect += 1\n        else:\n            neg_incorrect += 1\n       \n    if np.argmax(Y_validate[x]) == 0:\n        neg_cnt += 1\n    else:\n        pos_cnt += 1\n\nsensitivity = pos_correct/pos_cnt\nspecificity = neg_correct/neg_cnt\nprecision = pos_correct/(pos_correct + pos_incorrect)\nrecall = sensitivity\nf1 = (2 * precision * recall) / (precision + recall)\n\nprint(\"true positive rate: %.4f\" %(sensitivity) )\nprint(\"true negative rate: %.4f\" %(specificity) )\nprint(\"precision: %.4f\" %(precision))\nprint(\"recall: %.4f\" %(recall))\nprint(\"f1-score: %.4f\" %(f1))",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": "true positive rate: 0.7627\ntrue negative rate: 0.9712\nprecision: 1.0000\nrecall: 0.7627\nf1-score: 0.8654\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#predict sentiment of random example\ntwt = ['Meetings: Because none of us is as dumb as all of us.']\n#vectorizing the tweet by the pre-fitted tokenizer instance\ntwt = tokenizer.texts_to_sequences(twt)\n#padding the tweet to have exactly the same shape as `embedding_2` input\ntwt = pad_sequences(twt, maxlen=33, dtype='int32', value=0)\nprint(twt)\nsentiment = model.predict(twt,batch_size=1,verbose = 2)[0]\nif(np.argmax(sentiment) == 0):\n    print(\"negative\")\nelif (np.argmax(sentiment) == 1):\n    print(\"positive\")",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": "[[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n     0    0    0    0    0    0    0 1816  110  937   17   56   14   87\n  1860   87   58   17   56]]\nnegative\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python36",
      "display_name": "Python 3.6",
      "language": "python"
    },
    "language_info": {
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "name": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6",
      "file_extension": ".py",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}